{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "session4_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rk0803/END2/blob/Assignment1/session4_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jofyc9OC4Qcf"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahBVnrNc3E0U"
      },
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "plt.style.use('seaborn-white')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crQSAaIz4SkA"
      },
      "source": [
        "# Read and process data. \n",
        "\n",
        "Download the file from this URL: https://drive.google.com/file/d/1UWWIi-sz9g0x3LFvkIZjvK1r2ZaCqgGS/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "6_jGeEcg5_LE",
        "outputId": "e5827bd4-e1dd-4f63-c177-e20ca98aa43a"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5b5703ca-07d1-4f3a-98e4-5ea89a64c4ce\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5b5703ca-07d1-4f3a-98e4-5ea89a64c4ce\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving text.txt to text.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgOGxPDP3Wpp"
      },
      "source": [
        "data = open('text.txt', 'r').read()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeXXMLRb4kXb"
      },
      "source": [
        "Process data and calculate indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5TKeiOp4jtl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb9e9cd7-0a6b-4c38-8d1b-66d365e37c26"
      },
      "source": [
        "chars = list(set(data))\n",
        "data_size, X_size = len(data), len(chars)\n",
        "print(\"Corona Virus article has %d characters, %d unique characters\" %(data_size, X_size))\n",
        "char_to_idx = {ch:i for i,ch in enumerate(chars)}\n",
        "idx_to_char = {i:ch for i,ch in enumerate(chars)}"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corona Virus article has 10223 characters, 75 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C53MB135LRY"
      },
      "source": [
        "# Constants and Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfj21ORa49Ps"
      },
      "source": [
        "Hidden_Layer_size = 10 #size of the hidden layer\n",
        "Time_steps = 10 # Number of time steps (length of the sequence) used for training\n",
        "learning_rate = 1e-1 # Learning Rate\n",
        "weight_sd = 0.1 #Standard deviation of weights for initialization\n",
        "z_size = Hidden_Layer_size + X_size #Size of concatenation(H, X) vector"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdmJf4Du5uhb"
      },
      "source": [
        "# Activation Functions and Derivatives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seGHei_D5FGk"
      },
      "source": [
        "def sigmoid(x): # sigmoid function\n",
        "  return 1.0/(1+np.exp(-x))  # write your code here\n",
        "\n",
        "def dsigmoid(y): # derivative of sigmoid function\n",
        "  return sigmoid(y) * (1-sigmoid(y))# write your code here\n",
        "\n",
        "def tanh(x): # tanh function\n",
        "  return np.tanh(x) # write your code here\n",
        "\n",
        "def dtanh(y): # derivative of tanh\n",
        "  return 1-tanh(y)**2# write your code here"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xMwIiducfRv",
        "outputId": "2b47202a-aa23-46b3-e83c-7517c01d90d4"
      },
      "source": [
        "sigmoid(0)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zziQOjRdEyw",
        "outputId": "874e6699-68fb-4955-8763-917c7cb52594"
      },
      "source": [
        "dsigmoid(sigmoid(0))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2350037122015945"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CfSZqLddN9J",
        "outputId": "549f9359-ecc0-468c-b15e-b845d43cba33"
      },
      "source": [
        "tanh(dsigmoid(sigmoid(0)))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2307710272926824"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXdBWlNLdUWo",
        "outputId": "d8afff6d-1c7c-402b-abe2-397defba5148"
      },
      "source": [
        "dtanh(tanh(dsigmoid(sigmoid(0))))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9485799654066528"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeCvVH1v6Me-"
      },
      "source": [
        "# Quiz Question 1\n",
        "\n",
        "What is the value of sigmoid(0) calculated from  your code? (Answer up to 1 decimal point, e.g. 4.2 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "# Quiz Question 2\n",
        "\n",
        "What is the value of dsigmoid(sigmoid(0)) calculated from your code?? (Answer up to 2 decimal point, e.g. 4.29 and NOT 4.29999999, no rounding off). \n",
        "\n",
        "# Quiz Question 3\n",
        "\n",
        "What is the value of tanh(dsigmoid(sigmoid(0))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "# Quiz Question 4\n",
        "\n",
        "What is the value of dtanh(tanh(dsigmoid(sigmoid(0)))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeSVipDu8iKE"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICbWNemE6LGV"
      },
      "source": [
        "class Param:\n",
        "    def __init__(self, name, value):\n",
        "      self.name = name\n",
        "      self.v = value # parameter value\n",
        "      self.d = np.zeros_like(value) # derivative\n",
        "      self.m = np.zeros_like(value) # momentum for Adagrad"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j83pZNPE8212"
      },
      "source": [
        "We use random weights with normal distribution (0, weight_sd) for  tanh  activation function and (0.5, weight_sd) for  `sigmoid`  activation function.\n",
        "\n",
        "Biases are initialized to zeros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swHwLXOI9E7V"
      },
      "source": [
        "# LSTM \n",
        "You are making this network, please note f, i, c and o (also \"v\") in the image below:\n",
        "![alt text](http://blog.varunajayasiri.com/ml/lstm.svg)\n",
        "\n",
        "Please note that we are concatenating the old_hidden_vector and new_input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0DBzNY-90s5"
      },
      "source": [
        "# Quiz Question 4\n",
        "\n",
        "In the class definition below, what should be size_a, size_b, and size_c? ONLY use the variables defined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFuHhqVq6Wge"
      },
      "source": [
        "size_a = Hidden_Layer_size  # write your code here\n",
        "size_b = z_size  # write your code here\n",
        "size_c = X_size  # write your code here\n",
        "\n",
        "class Parameters:\n",
        "    def __init__(self):\n",
        "        self.W_f = Param('W_f', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_f = Param('b_f', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_i = Param('W_i', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_i = Param('b_i', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_C = Param('W_C', np.random.randn(size_a, size_b) * weight_sd)\n",
        "        self.b_C = Param('b_C', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_o = Param('W_o', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_o = Param('b_o', np.zeros((size_a, 1)))\n",
        "\n",
        "        #For final layer to predict the next character\n",
        "        self.W_v = Param('W_v', np.random.randn(X_size, size_a) * weight_sd)\n",
        "        self.b_v = Param('b_v', np.zeros((size_c, 1)))\n",
        "        \n",
        "    def all(self):\n",
        "        return [self.W_f, self.W_i, self.W_C, self.W_o, self.W_v,\n",
        "               self.b_f, self.b_i, self.b_C, self.b_o, self.b_v]\n",
        "        \n",
        "parameters = Parameters()"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzmfGLZt_xVs"
      },
      "source": [
        "Look at these operations which we'll be writing:\n",
        "\n",
        "**Concatenation of h and x:**\n",
        "\n",
        "$z\\:=\\:\\left[h_{t-1},\\:x\\right]$\n",
        "\n",
        "$f_t=\\sigma\\left(W_f\\cdot z\\:+\\:b_f\\:\\right)$\n",
        "\n",
        "$i_i=\\sigma\\left(W_i\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$\\overline{C_t}=\\tanh\\left(W_C\\cdot z\\:+\\:b_C\\right)$\n",
        "\n",
        "$C_t=f_t\\ast C_{t-1}+i_t\\ast \\overline{C}_t$\n",
        "\n",
        "$o_t=\\sigma\\left(W_o\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$h_t=o_t\\ast\\tanh\\left(C_t\\right)$\n",
        "\n",
        "**Logits:**\n",
        "\n",
        "$v_t=W_v\\cdot h_t+b_v$\n",
        "\n",
        "**Softmax:**\n",
        "\n",
        "$\\hat{y}=softmax\\left(v_t\\right)$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bUkseNnDott"
      },
      "source": [
        "def forward(x, h_prev, C_prev, p = parameters):\n",
        "    assert x.shape == (X_size, 1)\n",
        "    assert h_prev.shape == (Hidden_Layer_size, 1)\n",
        "    assert C_prev.shape == (Hidden_Layer_size, 1)\n",
        "    \n",
        "    z = np.row_stack((h_prev, x))\n",
        "    f = sigmoid(np.dot(p.W_f.v, z) + p.b_f.v) # write your code here\n",
        "    i = sigmoid(np.dot(p.W_i.v,z) + p.b_i.v) # write your code here\n",
        "    C_bar = tanh(np.dot(p.W_C.v,z) + p.b_C.v) # write your code here\n",
        "\n",
        "    C = f*C_prev + i*C_bar # write your code here\n",
        "    o = sigmoid(np.dot(p.W_o.v,z) + p.b_o.v) # write your code here\n",
        "    h = (o*tanh(C)) # write your code here\n",
        "\n",
        "    v = np.dot(p.W_v.v, h) + p.b_v.v # write your code here\n",
        "    y = np.exp(v) / np.sum(np.exp(v)) #softmax\n",
        "\n",
        "    return z, f, i, C_bar, C, o, h, v, y"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPFVOJ6X8FgJ",
        "outputId": "707cf87a-e961-4a40-9d17-2dc75ae5de31"
      },
      "source": [
        "print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3i5r7ST0qwj"
      },
      "source": [
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8-9dsHO0tY3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de28b2f9-98dd-4dc7-c27b-a15e4c7db034"
      },
      "source": [
        "print(z.shape)\n",
        "print(np.sum(z))\n",
        "print(np.sum(f))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(85, 1)\n",
            "0.0\n",
            "5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZrDhZIjFpdI"
      },
      "source": [
        "You must finish the function above before you can attempt the questions below. \n",
        "\n",
        "# Quiz Question 5\n",
        "\n",
        "What is the output of 'print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))'?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV-YVl_GGiX8"
      },
      "source": [
        "# Quiz Question 6. \n",
        "\n",
        "Assuming you have fixed the forward function, run this command: \n",
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))\n",
        "\n",
        "Now, find these values:\n",
        "\n",
        "\n",
        "1.   print(z.shape)\n",
        "2.   print(np.sum(z))\n",
        "3.   print(np.sum(f))\n",
        "\n",
        "Copy and paste exact values you get in the logs into the quiz.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GvKVWmTDt3H"
      },
      "source": [
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeSvhkqwILsG"
      },
      "source": [
        "# Backpropagation\n",
        "\n",
        "Here we are defining the backpropagation. It's too complicated, here is the whole code. (Please note that this would work only if your earlier code is perfect)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIa1jUZiGPmF"
      },
      "source": [
        "def backward(target, dh_next, dC_next, C_prev,\n",
        "             z, f, i, C_bar, C, o, h, v, y,\n",
        "             p = parameters):\n",
        "    \n",
        "    assert z.shape == (X_size + Hidden_Layer_size, 1)\n",
        "    assert v.shape == (X_size, 1)\n",
        "    assert y.shape == (X_size, 1)\n",
        "    \n",
        "    for param in [dh_next, dC_next, C_prev, f, i, C_bar, C, o, h]:\n",
        "        assert param.shape == (Hidden_Layer_size, 1)\n",
        "        \n",
        "    dv = np.copy(y)\n",
        "    dv[target] -= 1\n",
        "\n",
        "    p.W_v.d += np.dot(dv, h.T)\n",
        "    p.b_v.d += dv\n",
        "\n",
        "    dh = np.dot(p.W_v.v.T, dv)        \n",
        "    dh += dh_next\n",
        "    do = dh * tanh(C)\n",
        "    do = dsigmoid(o) * do\n",
        "    p.W_o.d += np.dot(do, z.T)\n",
        "    p.b_o.d += do\n",
        "\n",
        "    dC = np.copy(dC_next)\n",
        "    dC += dh * o * dtanh(tanh(C))\n",
        "    dC_bar = dC * i\n",
        "    dC_bar = dtanh(C_bar) * dC_bar\n",
        "    p.W_C.d += np.dot(dC_bar, z.T)\n",
        "    p.b_C.d += dC_bar\n",
        "\n",
        "    di = dC * C_bar\n",
        "    di = dsigmoid(i) * di\n",
        "    p.W_i.d += np.dot(di, z.T)\n",
        "    p.b_i.d += di\n",
        "\n",
        "    df = dC * C_prev\n",
        "    df = dsigmoid(f) * df\n",
        "    p.W_f.d += np.dot(df, z.T)\n",
        "    p.b_f.d += df\n",
        "\n",
        "    dz = (np.dot(p.W_f.v.T, df)\n",
        "         + np.dot(p.W_i.v.T, di)\n",
        "         + np.dot(p.W_C.v.T, dC_bar)\n",
        "         + np.dot(p.W_o.v.T, do))\n",
        "    dh_prev = dz[:Hidden_Layer_size, :]\n",
        "    dC_prev = f * dC\n",
        "    \n",
        "    return dh_prev, dC_prev"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnc7WpRkIU5S"
      },
      "source": [
        "# Forward and Backward Combined Pass\n",
        "\n",
        "Let's first clear the gradients before each backward pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJWoC3U1ITf8"
      },
      "source": [
        "def clear_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.d.fill(0)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XN93UnjIgmA"
      },
      "source": [
        "Clip gradients to mitigate exploding gradients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LTsublxIfFl"
      },
      "source": [
        "def clip_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        np.clip(p.d, -1, 1, out=p.d)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7XUpDTWIl_Y"
      },
      "source": [
        "Calculate and store the values in forward pass. Accumulate gradients in backward pass and clip gradients to avoid exploding gradients.\n",
        "\n",
        "input, target are list of integers, with character indexes.\n",
        "h_prev is the array of initial h at  h−1  (size H x 1)\n",
        "C_prev is the array of initial C at  C−1  (size H x 1)\n",
        "Returns loss, final  hT  and  CT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQNxjTuZIia_"
      },
      "source": [
        "def forward_backward(inputs, targets, h_prev, C_prev):\n",
        "    global paramters\n",
        "    \n",
        "    # To store the values for each time step\n",
        "    x_s, z_s, f_s, i_s,  = {}, {}, {}, {}\n",
        "    C_bar_s, C_s, o_s, h_s = {}, {}, {}, {}\n",
        "    v_s, y_s =  {}, {}\n",
        "    \n",
        "    # Values at t - 1\n",
        "    h_s[-1] = np.copy(h_prev)\n",
        "    C_s[-1] = np.copy(C_prev)\n",
        "    \n",
        "    loss = 0\n",
        "    # Loop through time steps\n",
        "    assert len(inputs) == Time_steps\n",
        "    for t in range(len(inputs)):\n",
        "        x_s[t] = np.zeros((X_size, 1))\n",
        "        x_s[t][inputs[t]] = 1 # Input character\n",
        "        \n",
        "        (z_s[t], f_s[t], i_s[t],\n",
        "        C_bar_s[t], C_s[t], o_s[t], h_s[t],\n",
        "        v_s[t], y_s[t]) = \\\n",
        "            forward(x_s[t], h_s[t - 1], C_s[t - 1]) # Forward pass\n",
        "            \n",
        "        loss += -np.log(y_s[t][targets[t], 0]) # Loss for at t\n",
        "        \n",
        "    clear_gradients()\n",
        "\n",
        "    dh_next = np.zeros_like(h_s[0]) #dh from the next character\n",
        "    dC_next = np.zeros_like(C_s[0]) #dh from the next character\n",
        "\n",
        "    for t in reversed(range(len(inputs))):\n",
        "        # Backward pass\n",
        "        dh_next, dC_next = \\\n",
        "            backward(target = targets[t], dh_next = dh_next,\n",
        "                     dC_next = dC_next, C_prev = C_s[t-1],\n",
        "                     z = z_s[t], f = f_s[t], i = i_s[t], C_bar = C_bar_s[t],\n",
        "                     C = C_s[t], o = o_s[t], h = h_s[t], v = v_s[t],\n",
        "                     y = y_s[t])\n",
        "\n",
        "    clip_gradients()\n",
        "        \n",
        "    return loss, h_s[len(inputs) - 1], C_s[len(inputs) - 1]"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcy5u_vRItkV"
      },
      "source": [
        "# Sample the next character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8SrtJiwIsSm"
      },
      "source": [
        "def sample(h_prev, C_prev, first_char_idx, sentence_length):\n",
        "    x = np.zeros((X_size, 1))\n",
        "    x[first_char_idx] = 1\n",
        "\n",
        "    h = h_prev\n",
        "    C = C_prev\n",
        "\n",
        "    indexes = []\n",
        "    \n",
        "    for t in range(sentence_length):\n",
        "        _, _, _, _, C, _, h, _, p = forward(x, h, C)\n",
        "        idx = np.random.choice(range(X_size), p=p.ravel())\n",
        "        x = np.zeros((X_size, 1))\n",
        "        x[idx] = 1\n",
        "        indexes.append(idx)\n",
        "\n",
        "    return indexes"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiWFaWLNIx_L"
      },
      "source": [
        "# Training (Adagrad)\n",
        "\n",
        "Update the graph and display a sample output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENQYU-7AIw0t"
      },
      "source": [
        "def update_status(inputs, h_prev, C_prev):\n",
        "    #initialized later\n",
        "    global plot_iter, plot_loss\n",
        "    global smooth_loss\n",
        "    \n",
        "    # Get predictions for 200 letters with current model\n",
        "\n",
        "    sample_idx = sample(h_prev, C_prev, inputs[0], 200)\n",
        "    txt = ''.join(idx_to_char[idx] for idx in sample_idx)\n",
        "\n",
        "    # Clear and plot\n",
        "    plt.plot(plot_iter, plot_loss)\n",
        "    display.clear_output(wait=True)\n",
        "    plt.show()\n",
        "\n",
        "    #Print prediction and loss\n",
        "    print(\"----\\n %s \\n----\" % (txt, ))\n",
        "    print(\"iter %d, loss %f\" % (iteration, smooth_loss))"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACXcASJuI73a"
      },
      "source": [
        "# Update Parameters\n",
        "\n",
        "\\begin{align}\n",
        "\\theta_i &= \\theta_i - \\eta\\frac{d\\theta_i}{\\sum dw_{\\tau}^2} \\\\\n",
        "d\\theta_i &= \\frac{\\partial L}{\\partial \\theta_i}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR08TvcjI4Pf"
      },
      "source": [
        "def update_paramters(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.m += p.d * p.d # Calculate sum of gradients\n",
        "        #print(learning_rate * dparam)\n",
        "        p.v += -(learning_rate * p.d / np.sqrt(p.m + 1e-8))"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La9vyJ6RJLFK"
      },
      "source": [
        "To delay the keyboard interrupt to prevent the training from stopping in the middle of an iteration\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVDHbMb7JNGT"
      },
      "source": [
        "# Exponential average of loss\n",
        "# Initialize to a error of a random model\n",
        "smooth_loss = -np.log(1.0 / X_size) * Time_steps\n",
        "\n",
        "iteration, pointer = 0, 0\n",
        "\n",
        "# For the graph\n",
        "plot_iter = np.zeros((0))\n",
        "plot_loss = np.zeros((0))"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF6vS0VWJqsS"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQyNSL0iJOxH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "outputId": "449941ea-3b77-4fac-8ee5-efc2f2b818a9"
      },
      "source": [
        "iter = 50000\n",
        "while iter > 0:\n",
        "  # Reset\n",
        "  if pointer + Time_steps >= len(data) or iteration == 0:\n",
        "      g_h_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      g_C_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      pointer = 0\n",
        "\n",
        "\n",
        "  inputs = ([char_to_idx[ch] \n",
        "              for ch in data[pointer: pointer + Time_steps]])\n",
        "  targets = ([char_to_idx[ch] \n",
        "              for ch in data[pointer + 1: pointer + Time_steps + 1]])\n",
        "\n",
        "  loss, g_h_prev, g_C_prev = \\\n",
        "      forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
        "  smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
        "\n",
        "  # Print every hundred steps\n",
        "  if iteration % 100 == 0:\n",
        "      update_status(inputs, g_h_prev, g_C_prev)\n",
        "\n",
        "  update_paramters()\n",
        "\n",
        "  plot_iter = np.append(plot_iter, [iteration])\n",
        "  plot_loss = np.append(plot_loss, [loss])\n",
        "\n",
        "  pointer += Time_steps\n",
        "  iteration += 1\n",
        "  iter = iter -1\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "----\n",
            " asorts Satsifho,iinh umeinilt.ptr t ots.or s iEi lwti,oan ar eddat aavt o t woyommyes bdb or ak T clvnfet cr2 emnieai,  ameOoE spa.ork8 Siosaanes n foryao.\n",
            "esp deen 8ic eseen elwti  .diyKold i ln ewio \n",
            "----\n",
            "iter 49900, loss 112.342828\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gR40mFrCUuVC",
        "outputId": "25d2d1db-1896-4cb0-ac92-00e6ec5a5c74"
      },
      "source": [
        "print(\"iter %d, loss %f\" % (iteration, smooth_loss))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter 50000, loss 112.300800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AKpa1BGOItQ"
      },
      "source": [
        "# Quiz Question 7. \n",
        "\n",
        "Run the above code for 50000 iterations making sure that you have 100 hidden layers and time_steps is 40. What is the loss value you're seeing?"
      ]
    }
  ]
}